Get the Codes here
Hi everyone,

Welcome to the practical activities of this extra Part on LLMs!

You can find all the codes here.



Also, please find below all the links to the Hugging Face tools we will use in this implementation:

The source dataset

The formatted dataset

The pre-trained Llama 2 model

The from_pretrained method from the AutoModelForCausalLM class

The BitsAndBytesConfig class from the transformers library

The from_pretrained method from the AutoTokenizer class

The TrainingArguments class from the transformers library

The SFTTrainer class from the trl library

The LoraConfig class from the peft library

The pipeline function from the transformers library



Cheers,

Kirill & Hadelin



PS: If you also need the codes in .ipynb and .py formats, please find them attached in the resources below.